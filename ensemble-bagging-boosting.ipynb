{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble & Bootstrap & Bagging & Boosting \n",
    "\n",
    "#### Ensemble \n",
    "여러 모델들을 결합하여 사용하면 Single 모델 보다 더 좋은 성능을 얻을 수 있다는 아이디어 \n",
    "\n",
    "높은 bias 로 인한 underfitting 과 높은 Variance로 인한 Overfitting 의 문제를 일종의 중간값으로 맞출수 있어 Overfitting피함 가능\n",
    "\n",
    "동일한 학습 알고리즘을 사용한 모델을 결합하면 앙상블 / 서로 다른 학습 모델을 결합하여 새로운 모델을 결합하면 Stacking 이라고 함\n",
    "\n",
    "#### Bootstrap\n",
    "중복을 허용하여 샘플 n개를 뽑는것\n",
    "\n",
    "#### Bagging \n",
    "Bagging(Bootstrap Aggregating) => 샘플을 여러번 뽑은 뒤 각 모델을 학습시켜 결과를 집계(Aggregating) 후 투표(voting)하여 가장 투표를 많이 받은 예측값 선택\n",
    "\n",
    "=> 복원 랜덤 샘플링하여 병렬적으로 모델 학습 후 집계하여 모델 생성 => 각 모델들 독립\n",
    "\n",
    "RandomForest => Decision Tree 여러개 말그대로 나무 많은 숲\n",
    "\n",
    "#### Boosting \n",
    "Boosting => 맞추기 어려운 문제에 초점. => 오답에 높은 가중치를 주어 오답에 집중 => but, 이상치 있으면 이거에 초점 맞춰서 이상치에 취약\n",
    "\n",
    "복원 램덤 샘플링을 하지만 가중치를 부여하여 순차적으로 학습을 시킴 => 이전 모델에 영향 받음 \n",
    "\n",
    "AdaBoost, GradientBoost, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
