{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 계수 \n",
    "0~1 사이의 값을 가지고 1에 가까울수록 설명력(회귀분석모델이 얼마나 데이터를 잘 설명해주는지)이 높음\n",
    "\n",
    "결정계수와 상관계수 차이\n",
    "\n",
    "인자가 하나일떄는 상관계수의 제곱값이 결정계수값\n",
    "\n",
    "보통결정계수를 상관계수의 제곱으로 구하긴 하지만 정확히는 결정계수는 상관계수와는 달리 여러 독립변수들이 종속변수를 설명하는지를 나타낸 \n",
    "수치라 다중 회귀분석에서는 다름 \n",
    "\n",
    "회귀분석에서 사용하는 수치임. \n",
    "\n",
    "따라서 독립변수가 여러개일떄는 제곱으로 정확하게 일치하지는 않음 \n",
    "\n",
    "수정된 결정계수 Adj. R-squared\n",
    "\n",
    "결정계수는 독립변수 개수가 많아질수록 그 값이 커짐. 따라서 표본크기와 독립변수의 수를 고려하여 계산하는데 이것이 수정된 결정계수\n",
    "\n",
    "독립변수 2개 이상이거나 표본 200개 미만이면 수정 결정계수를 보고서에 기술할것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.035\n",
      "Model:                            OLS   Adj. R-squared:                  0.032\n",
      "Method:                 Least Squares   F-statistic:                     11.25\n",
      "Date:                Thu, 17 Sep 2020   Prob (F-statistic):           0.000897\n",
      "Time:                        22:00:21   Log-Likelihood:                -1774.8\n",
      "No. Observations:                 309   AIC:                             3554.\n",
      "Df Residuals:                     307   BIC:                             3561.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        153.7898      4.312     35.669      0.000     145.306     162.274\n",
      "age          309.3540     92.237      3.354      0.001     127.857     490.851\n",
      "==============================================================================\n",
      "Omnibus:                       39.557   Durbin-Watson:                   2.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.331\n",
      "Skew:                           0.436   Prob(JB):                     6.34e-05\n",
      "Kurtosis:                       2.139   Cond. No.                         21.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "64606.22711810095  /  64606.22711810074\n",
      "1763236.9444029345  /  1763236.9444029348\n",
      "1827843.1715210355  /  1827843.1715210355\n",
      "0.035345607393843875 0.035345607393843737\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.397\n",
      "Model:                            OLS   Adj. R-squared:                  0.391\n",
      "Method:                 Least Squares   F-statistic:                     66.95\n",
      "Date:                Thu, 17 Sep 2020   Prob (F-statistic):           2.75e-33\n",
      "Time:                        22:00:21   Log-Likelihood:                -1702.2\n",
      "No. Observations:                 309   AIC:                             3412.\n",
      "Df Residuals:                     305   BIC:                             3427.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        153.3385      3.420     44.835      0.000     146.609     160.068\n",
      "age           43.5556     77.090      0.565      0.572    -108.139     195.251\n",
      "bmi          814.7085     78.339     10.400      0.000     660.555     968.862\n",
      "bp           332.2759     80.809      4.112      0.000     173.262     491.290\n",
      "==============================================================================\n",
      "Omnibus:                        5.746   Durbin-Watson:                   2.092\n",
      "Prob(Omnibus):                  0.057   Jarque-Bera (JB):                4.001\n",
      "Skew:                           0.130   Prob(JB):                        0.135\n",
      "Kurtosis:                       2.507   Cond. No.                         27.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "725759.8571189328  /  725759.8571189297\n",
      "1102083.3144021055  /  1102083.3144021058\n",
      "1827843.1715210355  /  1827843.1715210355\n",
      "0.3970580564168387 0.3970580564168371\n",
      "309 3\n",
      "0.391127479922578 / 0.39112747992257646\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import OLS, add_constant\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "datas = datasets.load_diabetes()\n",
    "datas.target\n",
    "df = pd.DataFrame(datas.data, columns = datas.feature_names)\n",
    "y = pd.DataFrame(datas.target, columns = ['y'])\n",
    "df = pd.concat([df, y], axis=1)\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=123)\n",
    "# 독립변수 1개일떄\n",
    "train_x = add_constant(train.age)\n",
    "model = OLS(train.y, train_x).fit()\n",
    "print(model.summary())\n",
    "# 오차는 실제값 - 예측값 => Regression 예측력\n",
    "# 편차는 실제값 - 평균값 => 그냥 평균잡았을때 예측력\n",
    "\n",
    "# RSS(Regression sum of squares) = ESS(explained sum of squares) : 회귀식과 평균값의 차이 => 이정도는 설명했다는 의미\n",
    "RSS = np.sum((model.predict(train_x) - train.y.mean())**2)\n",
    "print(RSS, ' / ' ,model.ess)\n",
    "# 잔차(오차) 제곱 합\n",
    "# SSE(Sum of squared errors) = RSS(residual sum of squares) : 회귀식과 실제값의 차이(회귀식에서 구한 값(예측치)과 실제값의 차이) => 예측해도 차이나는 에러 \n",
    "SSE = np.sum((train.y-model.predict(train_x))**2)\n",
    "print(SSE, ' / ', model.ssr)\n",
    "\n",
    "# TSS(Total sum of squares) : 편차 제곱합\n",
    "# TSS = RSS + SSE \n",
    "TSS = np.sum((train.y - train.y.mean())**2)\n",
    "print(TSS, ' / ', model.centered_tss)\n",
    "# r2 = RSS / TSS : 이정도는 설명 했다.\n",
    "r2 = RSS / TSS\n",
    "print(r2, model.rsquared)\n",
    "\n",
    "print('\\n~~~~~~~~~~~~~~~~~~~~\\n')\n",
    "# 독립변수 2개 이상일때\n",
    "train_x = add_constant(train[['age','bmi', 'bp']])\n",
    "model = OLS(train.y, train_x).fit()\n",
    "print(model.summary())\n",
    "# RSS(Regression sum of squares) = ESS(explained sum of squares) : 회귀식과 평균값의 차이 => 이정도는 설명했다는 의미\n",
    "RSS = np.sum((model.predict(train_x) - train.y.mean())**2)\n",
    "print(RSS, ' / ' , model.ess)\n",
    "# 잔차 제곱 합\n",
    "# SSE(Sum of squared errors) = RSS(residual sum of squares) : 회귀식과 실제값의 차이(회귀식에서 구한 값(예측치)과 실제값의 차이) => 예측해도 차이나는 에러 \n",
    "SSE = np.sum((train.y-model.predict(train_x))**2)\n",
    "print(SSE, ' / ', model.ssr)\n",
    "\n",
    "# TSS(Total sum of squares) : 편차 제곱합\n",
    "# TSS = RSS + SSE \n",
    "TSS = np.sum((train.y - train.y.mean())**2)\n",
    "print(TSS, ' / ', model.centered_tss)\n",
    "# r2 = RSS / TSS : 이정도는 설명 했다.\n",
    "r2 = RSS / TSS\n",
    "print(r2, model.rsquared)\n",
    "\n",
    "# 수정된 결정 계수 => 결정계수는 독립변수 개수가 많아질수록 그 값이 커지게 됨 => 보정한것이 수정된 결정 계수\n",
    "# 즉 표본의 크기와 독립변수의 수를 고려하여 계산하는것(n: 전체 샘플 개수, p: 설명변수 개수)\n",
    "# adjusted r2 = 1 - ((n-1)**(1-r2))/(n-p-1)\n",
    "n = len(train_x)\n",
    "p = len(train_x.columns)-1\n",
    "print(n, p)\n",
    "adjusted_r2 = 1 - ((n-1)*(1-r2))/(n-p-1)\n",
    "print(adjusted_r2 , '/', model.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
